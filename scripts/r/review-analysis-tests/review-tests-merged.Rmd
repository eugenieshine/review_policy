---
title: 'Review Analysis Tests: Tables on Review Length Test and Review Count Test by Product'
author: "Eugenie"
date: "12/10/2019"
output: 
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Source File

Data pre-processing is included, where special chars and minimal stop-words are removed.
```{r echo=T, results='hide', message=F, warning=F}
library(data.table)
## load review data
source("~/Dropbox/Eugenie/scripts/libs.R")
```

Load data.
```{r, include=FALSE}
reviews3.csv <- read.csv("~/Dropbox/Eugenie/data/processed/merged-reviews.csv")
reviews3.csv$date <- as.Date(reviews3.csv$date, "%Y-%m-%d")
```


# Data Processing
Add category data as extra columns. Join on either item_id or child_id.
```{r, include=FALSE}
reviews3.temp <- reviews3.csv
```

Drop records before 2012.
```{r, include=FALSE}
reviews3.temp <- reviews3.temp[as.numeric(as.character(reviews3.temp$year))>2013,]
```

Drop records after 2018-10-07 since it's not a full week.
```{r, include=FALSE}
#reviews3.temp <- reviews3.temp[reviews3.temp$date < '2018-10-07',]
```

Drop records with no product category.
```{r, include=FALSE}
reviews3.temp <- reviews3.temp[reviews3.temp$product_cat != 'none',]
```

Get selected columns for further analysis.
```{r, include=FALSE}
reviews.product <- reviews3.temp[,c('recid','item_id','incentivized','product_cat','rating','word_count','helpful_yes','date','year','month','week')]

## for pulling data
#reviews.product <- merge(aws_reviews,reviews3.temp[,c('recid','item_id','product_cat','word_count','year','month','week','date')])

reviews.product['after_ban'] <- ifelse(reviews.product$date>'2016-10-02',1,0)
reviews.product$after_ban <- as.factor(reviews.product$after_ban)
levels(reviews.product$after_ban) <- c("before", "after")
```


# Analysis Test: Daily Average Review Count

## Data Processing
First, we estimate the number of days the product has been available for review by counting the number of days from the first review to the last review.

```{r, include=FALSE}
reviews.product <- reviews.product %>%
  group_by(item_id) %>%
  mutate(total_num.days=difftime(max(date), min(date)))
```

Get the daily number of reviews per item.
```{r, include=FALSE}
reviews.daily <- reviews.product %>%
  group_by(item_id, date) %>%
  summarise(daily.count = n())

time.diff <- reviews.product[,c('item_id','date')] %>%
  group_by(item_id) %>%
  mutate(first_review.date = min(date)) %>%
  mutate(last_review.date = max(date))

time.diff <- time.diff[,c('item_id','first_review.date','last_review.date')] %>%
  distinct()

reviews.first_last_date <- time.diff

## creating dates based on the first and last review per item
time.diff <- setDT(time.diff)[, .(date = seq(first_review.date, last_review.date, by = "day")), 
                              by = item_id]

reviews.daily <- merge(time.diff, reviews.daily, by=c('item_id','date'), all.x = T)
reviews.daily[is.na(reviews.daily)] <- 0
```

Get mean, variance, and standard deviation of the number of reviews per day by item.
```{r, include=FALSE}
reviews.daily <- reviews.daily %>%
  group_by(item_id) %>%
  mutate(sd = sd(daily.count)) %>%
  mutate(variance = var(daily.count)) %>%
  mutate(mean = mean(daily.count))
```

Get the number of daily reviews that is 2 and 3 sd's away.
```{r, include=FALSE}
reviews.daily <- reviews.daily %>%
  group_by(item_id) %>%
  mutate(threshold_3sd = mean+3*sd) %>%
  mutate(threshold_2sd = mean+2*sd)

#write.csv(reviews.daily, file = "reviews3-count-test-stats.csv",row.names=FALSE)
#reviews.daily['threshold.ceil'] <- ceiling(reviews.daily$threshold)
```

Get the item_id and days where the number of daily reviews is above the threshold.
```{r, include=FALSE}
reviews.over_2sd <- reviews.daily[reviews.daily$daily.count>reviews.daily$threshold_2sd,]
reviews.over_3sd <- reviews.daily[reviews.daily$daily.count>reviews.daily$threshold_3sd,]

reviews.over_2sd <- reviews.over_2sd %>%
  group_by(item_id) %>%
  mutate(num.days=n())
reviews.over_3sd <- reviews.over_3sd %>%
  group_by(item_id) %>%
  mutate(num.days=n())
```

Join results with initial data frame.
```{r, include=FALSE}
reviews.over_2sd['review_count.2sd'] <- 1
reviews.over_3sd['review_count.3sd'] <- 1

reviews.product <- merge(reviews.product, reviews.over_2sd[,c('item_id','date','review_count.2sd')],
                         by=c('item_id','date'), all.x = T)
reviews.product <- merge(reviews.product, reviews.over_3sd[,c('item_id','date','review_count.3sd')],
                         by=c('item_id','date'), all.x = T)

reviews.product[is.na(reviews.product)] <- 0

reviews.product$review_count.2sd <- as.factor(reviews.product$review_count.2sd)
levels(reviews.product$review_count.2sd) <- c("pass", "fail")
reviews.product$review_count.3sd <- as.factor(reviews.product$review_count.3sd)
levels(reviews.product$review_count.3sd) <- c("pass", "fail")
```

Join review.daily statistics and review.product
```{r,echo=FALSE}
reviews.count <- reviews.daily[,!(names(reviews.daily) %in% c('date', 'daily.count'))]
reviews.count <- reviews.count %>% distinct()
reviews.count <- merge(reviews.product, reviews.count, by = 'item_id')
```


## Result Analysis

### Two standard deviations away

```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','review_count.2sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$review_count.2sd <- paste0(temp$after_ban,'_',temp$review_count.2sd)
temp <- temp[,c('product_cat','review_count.2sd','Freq')]
#knitr::kable(ddply(temp, .(review_count.2sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('review_count.2sd'), direction = "wide")

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

knitr::kable(table.length)
```

Mean review rating for over vs. under daily threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.product[, 'rating'], list(reviews.product$product_cat,reviews.product$review_count.2sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.product, aes(review_count.2sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```

Linear Regression with Fixed Effect on Item ID

```{r, include=FALSE}
formula.fe <- rating ~ review_count.2sd
```

```{r, results='asis', echo=FALSE}
# in model.fe, index = c('item_id') defines 'item_id' as the entity
model.fe <- plm(data = reviews.product, formula = formula.fe, index = c('item_id'), model = 'within')

# get the model summary
stargazer(model.fe,title='Linear Regression with Fixed Effect: Daily Review Count', 
          align=TRUE, type = 'html')
```
From the result of the linear fixed effect modelling, the null hypothesis of the independency of products is rejected. 

### Three standard deviations away

```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','review_count.3sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$review_count.3sd <- paste0(temp$after_ban,'_',temp$review_count.3sd)
temp <- temp[,c('product_cat','review_count.3sd','Freq')]
#knitr::kable(ddply(temp, .(review_count.2sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('review_count.3sd'), direction = "wide")

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

knitr::kable(table.length)
```

Mean review rating for over vs. under daily threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.product[, 'rating'], list(reviews.product$product_cat,reviews.product$review_count.3sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.product, aes(review_count.3sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```

Linear Regression with Fixed Effect on Item ID

```{r, include=FALSE}
formula.fe <- rating ~ review_count.3sd
```

```{r, results='asis', echo=FALSE}
# in model.fe, index = c('item_id') defines 'item_id' as the entity
model.fe <- plm(data = reviews.product, formula = formula.fe, index = c('item_id'), model = 'within')

# get the model summary
stargazer(model.fe,title='Linear Regression with Fixed Effect: Daily Review Count', 
          align=TRUE, type = 'html')
```
From the result of the linear fixed effect modelling, the null hypothesis of the independency of products is rejected. 

# Analysis Test: Average Review Length
Once we have the word count distribution of the product and the expected distribution of the category we compare the two distributions and identify product word count groups that are higher in concentration than weâ€™d expect to see.

## Data Processing

Get mean, variance, and standard deviation of the number of reviews per day by item.
```{r, include=FALSE}
reviews.length <- reviews.product %>%
  group_by(product_cat) %>%
  mutate(sd = sd(word_count)) %>%
  mutate(variance = var(word_count)) %>%
  mutate(mean = mean(word_count))

```

Compute stds
```{r,echo=FALSE}
reviews.length <- reviews.length %>%
  group_by(product_cat) %>%
  mutate(threshold_2sd = mean+2*sd) %>%
  mutate(threshold_3sd = mean+3*sd)
```

Label pass/fail lests
```{r,echo=FALSE}
reviews.length['word_count.2sd'] <- ifelse(reviews.length$word_count>reviews.length$threshold_2sd, 'fail', 'pass')
reviews.length['word_count.3sd'] <- ifelse(reviews.length$word_count>reviews.length$threshold_3sd, 'fail', 'pass')
```

Merge the result with review.product
```{r,echo=FALSE}
reviews.product <- merge(reviews.product, reviews.length[,c('recid','word_count.2sd','word_count.3sd')],
                         by=c('recid'), all.x = T)
```


## Result Analysis

### Two standard deviations away

```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','word_count.2sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$word_count.2sd <- paste0(temp$after_ban,'_',temp$word_count.2sd)
temp <- temp[,c('product_cat','word_count.2sd','Freq')]
#knitr::kable(ddply(temp, .(word_count.2sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('word_count.2sd'), direction = "wide")

temp <- reviews.length[,c('product_cat','mean','variance','sd','threshold_2sd')] %>% distinct()

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

table.length <- merge(table.length, temp, by = 'product_cat')
knitr::kable(table.length)
```

Mean review rating for over vs. under length threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.length[, 'rating'], list(reviews.length$product_cat,reviews.length$word_count.2sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.length, aes(word_count.2sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```


### Three standard deviations away
```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','word_count.3sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$word_count.3sd <- paste0(temp$after_ban,'_',temp$word_count.3sd)
temp <- temp[,c('product_cat','word_count.3sd','Freq')]
#knitr::kable(ddply(temp, .(word_count.3sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('word_count.3sd'), direction = "wide")

temp <- reviews.length[,c('product_cat','mean','variance','sd','threshold_3sd')] %>% distinct()

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

table.length <- merge(table.length, temp, by = 'product_cat')
knitr::kable(table.length)
```

Mean review rating for over vs. under length threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.length[, 'rating'], list(reviews.length$product_cat,reviews.length$word_count.3sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.length, aes(word_count.3sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```


