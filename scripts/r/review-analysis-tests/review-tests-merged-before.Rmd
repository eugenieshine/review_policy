---
title: 'Review Analysis Tests: Tables on Review Length Test and Review Count Test by Product'
author: "Eugenie"
date: "19/10/2019"
output: 
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Source File

Data pre-processing is included, where special chars and minimal stop-words are removed.
```{r echo=T, results='hide', message=F, warning=F}
library(data.table)
## load review data
source("~/Dropbox/Eugenie/scripts/libs.R")
```

Load data.
```{r, include=FALSE}
reviews3.csv <- read.csv("~/Dropbox/Eugenie/data/processed/merged-reviews.csv")
reviews3.csv$date <- as.Date(reviews3.csv$date, "%Y-%m-%d")
```


# Data Processing
```{r, include=FALSE}
reviews3.temp <- reviews3.csv
```

```{r, include=FALSE}
#Drop records before 2013.
reviews3.temp <- reviews3.temp[as.numeric(as.character(reviews3.temp$year))>2013,]
```

```{r, include=FALSE}
# Drop records with no product category.
reviews3.temp <- reviews3.temp[reviews3.temp$product_cat != 'none',]
```

```{r, include=FALSE}
# Get selected columns for further analysis.
reviews.product <- reviews3.temp[,c('recid','item_id','incentivized','product_cat','rating','word_count','helpful_yes','date','year','month','week')]

## for pulling data
#reviews.product <- merge(aws_reviews,reviews3.temp[,c('recid','item_id','product_cat','word_count','year','month','week','date')])

reviews.product['after_ban'] <- ifelse(reviews.product$date>'2016-10-02',1,0)
reviews.product$after_ban <- as.factor(reviews.product$after_ban)
levels(reviews.product$after_ban) <- c("before", "after")
```


# Analysis Test: Daily Average Review Count

## Data Processing
```{r, include=FALSE}
# Get the daily number of reviews per item.
reviews.daily <- reviews.product %>%
  group_by(item_id, date) %>%
  summarise(daily.count = n())

time.diff <- reviews.product[,c('item_id','date')] %>%
  group_by(item_id) %>%
  mutate(first_review.date = min(date)) %>%
  mutate(last_review.date = max(date))

time.diff <- time.diff[,c('item_id','first_review.date','last_review.date')] %>%
  distinct()

reviews.first_last_date <- time.diff

## creating dates based on the first and last review per item
time.diff <- setDT(time.diff)[, .(date = seq(first_review.date, last_review.date, by = "day")), 
                              by = item_id]

reviews.daily <- merge(time.diff, reviews.daily, by=c('item_id','date'), all.x = T)
reviews.daily[is.na(reviews.daily)] <- 0
```

```{r, include=FALSE}
# Get mean, variance, and standard deviation of the number of reviews per day by item.
reviews.daily_stats <- reviews.daily[reviews.daily$date < "2016-10-04",] %>%
  group_by(item_id) %>%
  mutate(sd = sd(daily.count)) %>%
  mutate(variance = var(daily.count)) %>%
  mutate(mean = mean(daily.count))

reviews.daily_stats <- reviews.daily_stats[,c("item_id", "sd", "variance", "mean")] %>% distinct()
```

```{r, include=FALSE}
# Get the number of daily reviews that is 2 and 3 sd's away.
reviews.daily_stats <- reviews.daily_stats %>%
  group_by(item_id) %>%
  mutate(threshold_3sd = mean+3*sd) %>%
  mutate(threshold_2sd = mean+2*sd)

reviews.daily <- merge(reviews.daily, reviews.daily_stats, by = 'item_id')
#write.csv(reviews.daily, file = "reviews3-count-test-stats.csv",row.names=FALSE)
#reviews.daily['threshold.ceil'] <- ceiling(reviews.daily$threshold)
```

```{r, include=FALSE}
# Get the item_id and days where the number of daily reviews is above the threshold.
reviews.over_2sd <- reviews.daily[reviews.daily$daily.count>reviews.daily$threshold_2sd,]
reviews.over_3sd <- reviews.daily[reviews.daily$daily.count>reviews.daily$threshold_3sd,]

reviews.over_2sd <- reviews.over_2sd %>%
  group_by(item_id) %>%
  mutate(num.days=n())
reviews.over_3sd <- reviews.over_3sd %>%
  group_by(item_id) %>%
  mutate(num.days=n())
```

```{r, include=FALSE}
# Join results with initial data frame.
reviews.over_2sd['review_count.2sd'] <- 1
reviews.over_3sd['review_count.3sd'] <- 1

reviews.product <- merge(reviews.product, reviews.over_2sd[,c('item_id','date','review_count.2sd')],
                         by=c('item_id','date'), all.x = T)
reviews.product <- merge(reviews.product, reviews.over_3sd[,c('item_id','date','review_count.3sd')],
                         by=c('item_id','date'), all.x = T)

reviews.product[is.na(reviews.product)] <- 0

reviews.product$review_count.2sd <- as.factor(reviews.product$review_count.2sd)
levels(reviews.product$review_count.2sd) <- c("pass", "fail")
reviews.product$review_count.3sd <- as.factor(reviews.product$review_count.3sd)
levels(reviews.product$review_count.3sd) <- c("pass", "fail")
```

```{r,echo=FALSE}
# Join review.daily statistics and review.product
reviews.count <- merge(reviews.product, reviews.daily_stats, by = 'item_id')
```


## Result Analysis

### Two standard deviations away

```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','review_count.2sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$review_count.2sd <- paste0(temp$after_ban,'_',temp$review_count.2sd)
temp <- temp[,c('product_cat','review_count.2sd','Freq')]
#knitr::kable(ddply(temp, .(review_count.2sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('review_count.2sd'), direction = "wide")

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

knitr::kable(table.length)
```

Mean review rating for over vs. under daily threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.product[, 'rating'], list(reviews.product$product_cat,reviews.product$review_count.2sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.product, aes(review_count.2sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```

Linear Regression with Fixed Effect on Item ID

```{r, include=FALSE}
formula.fe <- rating ~ review_count.2sd
```

```{r, results='asis', echo=FALSE}
# in model.fe, index = c('item_id') defines 'item_id' as the entity
model.fe <- plm(data = reviews.product, formula = formula.fe, index = c('item_id'), model = 'within')

# get the model summary
stargazer(model.fe,title='Linear Regression with Fixed Effect: Daily Review Count', 
          align=TRUE, type = 'html')
```
From the result of the linear fixed effect modelling, the null hypothesis of the independency of products is rejected. 

### Three standard deviations away

```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','review_count.3sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$review_count.3sd <- paste0(temp$after_ban,'_',temp$review_count.3sd)
temp <- temp[,c('product_cat','review_count.3sd','Freq')]
#knitr::kable(ddply(temp, .(review_count.2sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('review_count.3sd'), direction = "wide")

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

knitr::kable(table.length)
```

Mean review rating for over vs. under daily threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.product[, 'rating'], list(reviews.product$product_cat,reviews.product$review_count.3sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.product, aes(review_count.3sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```

Linear Regression with Fixed Effect on Item ID

```{r, include=FALSE}
formula.fe <- rating ~ review_count.3sd
```

```{r, results='asis', echo=FALSE}
# in model.fe, index = c('item_id') defines 'item_id' as the entity
model.fe <- plm(data = reviews.product, formula = formula.fe, index = c('item_id'), model = 'within')

# get the model summary
stargazer(model.fe,title='Linear Regression with Fixed Effect: Daily Review Count', 
          align=TRUE, type = 'html')
```
From the result of the linear fixed effect modelling, the null hypothesis of the independency of products is rejected. 

# Analysis Test: Average Review Length
Once we have the word count distribution of the product and the expected distribution of the category we compare the two distributions and identify product word count groups that are higher in concentration than weâ€™d expect to see.

## Data Processing

```{r, include=FALSE}
# Get mean, variance, and standard deviation of the number of reviews per day by item.
reviews.length <- reviews.product[reviews.product$after_ban == "before",] %>%
  group_by(product_cat) %>%
  mutate(sd = sd(word_count)) %>%
  mutate(variance = var(word_count)) %>%
  mutate(mean = mean(word_count))

reviews.length <- reviews.length[,c("product_cat", "sd", "variance", "mean")] %>% distinct()
```

```{r,echo=FALSE}
# Compute stds
reviews.length <- reviews.length %>%
  group_by(product_cat) %>%
  mutate(threshold_2sd = mean+2*sd) %>%
  mutate(threshold_3sd = mean+3*sd)
```

```{r,echo=FALSE}
# Label pass/fail lests
reviews.product <- merge(reviews.product, reviews.length, by = 'product_cat')
reviews.product['word_count.2sd'] <- ifelse(reviews.product$word_count>reviews.product$threshold_2sd, 'fail', 'pass')
reviews.product['word_count.3sd'] <- ifelse(reviews.product$word_count>reviews.product$threshold_3sd, 'fail', 'pass')
```


## Result Analysis

### Two standard deviations away

```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','word_count.2sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$word_count.2sd <- paste0(temp$after_ban,'_',temp$word_count.2sd)
temp <- temp[,c('product_cat','word_count.2sd','Freq')]
#knitr::kable(ddply(temp, .(word_count.2sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('word_count.2sd'), direction = "wide")

temp <- reviews.length[,c('product_cat','mean','variance','sd','threshold_2sd')] %>% distinct()

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

table.length <- merge(table.length, temp, by = 'product_cat')
knitr::kable(table.length)
```

Review length after ban.
```{r,echo=FALSE}
# Get mean, variance, and standard deviation of the number of reviews per day by item.
reviews.length.after <- reviews.product[reviews.product$after_ban == "after",] %>%
  group_by(product_cat) %>%
  mutate(sd = sd(word_count)) %>%
  mutate(variance = var(word_count)) %>%
  mutate(mean = mean(word_count))

reviews.length.after <- reviews.length.after[,c("product_cat", "sd", "variance", "mean")] %>% distinct()
knitr::kable(reviews.length.after)
```

Mean review rating for over vs. under length threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.product[, 'rating'], list(reviews.product$product_cat,reviews.product$word_count.2sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.product, aes(word_count.2sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```


### Three standard deviations away
```{r,echo=FALSE}
temp <- data.frame(table(reviews.product[,c('product_cat','after_ban','word_count.3sd')]))
temp<-temp[!(temp$product_cat=="none"),]
temp$word_count.3sd <- paste0(temp$after_ban,'_',temp$word_count.3sd)
temp <- temp[,c('product_cat','word_count.3sd','Freq')]
#knitr::kable(ddply(temp, .(word_count.3sd), mutate, Freq_pct = Freq/sum(Freq)*100))
```

```{r,echo=FALSE}
table.length <- reshape(temp, idvar = "product_cat", timevar = c('word_count.3sd'), direction = "wide")

temp <- reviews.product[,c('product_cat','mean','variance','sd','threshold_3sd')] %>% distinct()

table.length <- table.length %>%
  group_by(product_cat) %>%
  mutate(Before.fail.pct = Freq.before_fail/(Freq.before_pass+Freq.before_fail)*100) %>%
  mutate(After.fail.pct = Freq.after_fail/(Freq.after_pass+Freq.after_fail)*100)

table.length <- merge(table.length, temp, by = 'product_cat')
knitr::kable(table.length)
```

Mean review rating for over vs. under length threshold for the number of reviews.

```{r,echo=FALSE}
product.avg <- aggregate(reviews.product[, 'rating'], list(reviews.product$product_cat,reviews.product$word_count.3sd), mean)
names(product.avg) <- c('product_cat','reviews.count','avg.rating')
product.avg <- reshape(product.avg, idvar = 'product_cat',timevar = 'reviews.count', direction = 'wide')
knitr::kable(product.avg)
```

Review distribution between groups.

```{r,echo=FALSE}
ggplot(data=reviews.product, aes(word_count.3sd))+
  geom_bar(aes(fill=as.factor(rating)), position="fill")+
  scale_fill_brewer(palette="RdBu", name='rating')+
  facet_grid(~product_cat)+
  ylab('proportion')
```


